(Topicos_IA) d:\Cursos de Universidad\Semestre 9\Top IA\Dataset\Scripts>python main.py
True
0
<torch.cuda.device object at 0x0000017E97497850>
1
NVIDIA GeForce RTX 3060 Laptop GPU
True
bert
finiteautomata/beto-sentiment-analysis
D:\Anaconda\Anaconda\envs\Topicos_IA\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epochs 0/15. Running Loss:    0.0009: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:59<00:00,  4.70it/s]
Epochs 1/15. Running Loss:    0.0016: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:58<00:00,  4.84it/s]
Epochs 2/15. Running Loss:    0.0013: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:56<00:00,  4.97it/s]
Epochs 3/15. Running Loss:    0.0111: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:03<00:00,  4.47it/s]
Epochs 4/15. Running Loss:    0.0002: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:04<00:00,  4.36it/s]
Epochs 5/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:03<00:00,  4.46it/s]
Epochs 6/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:06<00:00,  4.27it/s]
Epochs 7/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:03<00:00,  4.43it/s]
Epochs 8/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:03<00:00,  4.43it/s]
Epochs 9/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:01<00:00,  4.57it/s]
Epochs 10/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:02<00:00,  4.48it/s]
Epochs 11/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:54<00:00,  5.21it/s]
Epochs 12/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:06<00:00,  4.25it/s]
Epochs 13/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:06<00:00,  4.25it/s]
Epochs 14/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:06<00:00,  4.26it/s]
Epoch 15 of 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [15:37<00:00, 62.47s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:12<00:00, 22.99it/s]
True
distilbert
distilbert-base-multilingual-cased
Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
D:\Anaconda\Anaconda\envs\Topicos_IA\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epochs 0/15. Running Loss:    0.6251: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:40<00:00,  6.97it/s]
Epochs 1/15. Running Loss:    0.0494: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:40<00:00,  7.00it/s]
Epochs 2/15. Running Loss:    0.0150: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:40<00:00,  6.99it/s]
Epochs 3/15. Running Loss:    0.0060: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:40<00:00,  7.01it/s]
Epochs 4/15. Running Loss:    0.0023: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:40<00:00,  6.98it/s]
Epochs 5/15. Running Loss:    0.0022: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:40<00:00,  6.92it/s]
Epochs 6/15. Running Loss:    0.0004: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:36<00:00,  7.81it/s]
Epochs 7/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:36<00:00,  7.76it/s]
Epochs 8/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:36<00:00,  7.64it/s]
Epochs 9/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:37<00:00,  7.55it/s]
Epochs 10/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:37<00:00,  7.49it/s]
Epochs 11/15. Running Loss:    0.0001: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:37<00:00,  7.46it/s]
Epochs 12/15. Running Loss:    0.0001: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:37<00:00,  7.57it/s]
Epochs 13/15. Running Loss:    0.0001: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:38<00:00,  7.40it/s]
Epochs 14/15. Running Loss:    0.0001: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:38<00:00,  7.41it/s]
Epoch 15 of 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [09:38<00:00, 38.54s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:06<00:00, 42.31it/s]
True
bert
bert-base-multilingual-cased
Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
D:\Anaconda\Anaconda\envs\Topicos_IA\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epochs 0/15. Running Loss:    0.4464: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:03<00:00,  4.47it/s]
Epochs 1/15. Running Loss:    0.7198: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:03<00:00,  4.42it/s]
Epochs 2/15. Running Loss:    0.6156: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:52<00:00,  5.42it/s]
Epochs 3/15. Running Loss:    0.6304: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:53<00:00,  5.27it/s]
Epochs 4/15. Running Loss:    1.4564: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:19<00:00,  3.56it/s]
Epochs 5/15. Running Loss:    0.3184: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:59<00:00,  2.37it/s]
Epochs 6/15. Running Loss:    0.7059: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:56<00:00,  2.41it/s]
Epochs 7/15. Running Loss:    0.1251: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:52<00:00,  2.51it/s]
Epochs 8/15. Running Loss:    0.2738: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:53<00:00,  2.49it/s]
Epochs 9/15. Running Loss:    0.2093: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:52<00:00,  2.51it/s]
Epochs 10/15. Running Loss:    2.4139: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:55<00:00,  2.44it/s]
Epochs 11/15. Running Loss:    3.0692: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:56<00:00,  2.42it/s]
Epochs 12/15. Running Loss:    0.0214: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:53<00:00,  2.48it/s]
Epochs 13/15. Running Loss:    0.0203: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:53<00:00,  2.48it/s]
Epochs 14/15. Running Loss:    0.0213: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:53<00:00,  2.48it/s]
Epoch 15 of 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [24:19<00:00, 97.31s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:19<00:00, 14.39it/s]
True
roberta
bertin-project/bertin-base-xnli-es
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at bertin-project/bertin-base-xnli-es and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
D:\Anaconda\Anaconda\envs\Topicos_IA\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epochs 0/15. Running Loss:    0.1748: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:38<00:00,  2.87it/s]
Epochs 1/15. Running Loss:    0.0296: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:27<00:00,  3.24it/s]
Epochs 2/15. Running Loss:    0.0055: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:28<00:00,  3.19it/s]
Epochs 3/15. Running Loss:    0.0030: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:33<00:00,  3.02it/s]
Epochs 4/15. Running Loss:    0.0022: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:35<00:00,  2.96it/s]
Epochs 5/15. Running Loss:    0.0010: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:35<00:00,  2.96it/s]
Epochs 6/15. Running Loss:    0.0005: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:35<00:00,  2.97it/s]
Epochs 7/15. Running Loss:    0.0004: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:35<00:00,  2.94it/s]
Epochs 8/15. Running Loss:    0.0005: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:36<00:00,  2.92it/s]
Epochs 9/15. Running Loss:    0.0003: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:22<00:00,  3.43it/s]
Epochs 10/15. Running Loss:    0.0004: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:30<00:00,  3.12it/s]
Epochs 11/15. Running Loss:    0.0003: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:32<00:00,  3.05it/s]
Epochs 12/15. Running Loss:    0.0004: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:31<00:00,  3.09it/s]
Epochs 13/15. Running Loss:    0.0004: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:30<00:00,  3.11it/s]
Epochs 14/15. Running Loss:    0.0002: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:35<00:00,  2.95it/s]
Epoch 15 of 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [23:07<00:00, 92.52s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:20<00:00, 13.81it/s]
True
distilbert
philschmid/distilbert-base-multilingual-cased-sentiment-2
D:\Anaconda\Anaconda\envs\Topicos_IA\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epochs 0/15. Running Loss:    0.0563: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:15<00:00,  3.73it/s]
Epochs 1/15. Running Loss:    0.0857: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:14<00:00,  3.78it/s]
Epochs 2/15. Running Loss:    0.0572: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:14<00:00,  3.78it/s]
Epochs 3/15. Running Loss:    0.0109: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:14<00:00,  3.81it/s]
Epochs 4/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:14<00:00,  3.77it/s]
Epochs 5/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:16<00:00,  3.69it/s]
Epochs 6/15. Running Loss:    0.0002: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:12<00:00,  3.87it/s]
Epochs 7/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:14<00:00,  3.79it/s]
Epochs 8/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:12<00:00,  3.89it/s]
Epochs 9/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:13<00:00,  3.82it/s]
Epochs 10/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:09<00:00,  4.05it/s]
Epochs 11/15. Running Loss:    0.0001: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:10<00:00,  3.99it/s]
Epochs 12/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:12<00:00,  3.90it/s]
Epochs 13/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:12<00:00,  3.91it/s]
Epochs 14/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:10<00:00,  3.99it/s]
Epoch 15 of 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [18:19<00:00, 73.28s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:09<00:00, 29.00it/s]
True
roberta
edumunozsala/RuPERTa_base_sentiment_analysis_es
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at edumunozsala/RuPERTa_base_sentiment_analysis_es and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
D:\Anaconda\Anaconda\envs\Topicos_IA\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
Epochs 0/15. Running Loss:    0.7654: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:32<00:00,  3.04it/s]
Epochs 1/15. Running Loss:    2.5254: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:27<00:00,  3.22it/s]
Epochs 2/15. Running Loss:    0.0181: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:31<00:00,  3.09it/s]
Epochs 3/15. Running Loss:    0.0033: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:31<00:00,  3.07it/s]
Epochs 4/15. Running Loss:    0.0007: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:37<00:00,  2.90it/s]
Epochs 5/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:36<00:00,  2.91it/s]
Epochs 6/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:37<00:00,  2.90it/s]
Epochs 7/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:35<00:00,  2.94it/s]
Epochs 8/15. Running Loss:    0.0001: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:07<00:00,  4.18it/s]
Epochs 9/15. Running Loss:    0.0000: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:05<00:00,  4.29it/s]
Epochs 10/15. Running Loss:    0.0001: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:04<00:00,  4.39it/s]
Epochs 11/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:59<00:00,  4.74it/s]
Epochs 12/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:08<00:00,  4.14it/s]
Epochs 13/15. Running Loss:    0.0000: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:22<00:00,  3.41it/s]
Epochs 14/15. Running Loss:    0.0002: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [01:39<00:00,  2.83it/s]
Epoch 15 of 15: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15/15 [20:57<00:00, 83.86s/it]
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 282/282 [00:19<00:00, 14.23it/s]